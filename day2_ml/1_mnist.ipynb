{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fn3JgSt19n3"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'lr'         : 0.01, # Coef to multiply gradients\n",
        "         'momentum'   : 0.5,  # SGD momentum (default: 0.5) - extra term in descent\n",
        "         'batch_size' : 512, # number of data samples to consider at once for training\n",
        "         'epochs'     : 20,   #The number of Epochs is the number of times you go through the full dataset.\n",
        "\n",
        "         }\n",
        "\n",
        "train_dataset = datasets.MNIST('./data',\n",
        "                               train=True,\n",
        "                               download=True,\n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "validation_dataset = datasets.MNIST('./data',\n",
        "                                    train=False,\n",
        "                                    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=param['batch_size'],\n",
        "                                           shuffle=True)\n",
        "\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset,\n",
        "                                                batch_size=param['batch_size'],\n",
        "                                                shuffle=False)"
      ],
      "metadata": {
        "id": "kabmqWQc2Lld"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check structure and dimension of data\n",
        "\n",
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "3sBdsPx92OMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot images\n",
        "\n",
        "pltsize=1\n",
        "plt.figure(figsize=(10*pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1,10,i+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(X_train[i,:,:,:].numpy().reshape(28,28), cmap=\"gray_r\")\n",
        "    plt.title('Class: '+str(y_train[i].item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "-BLewlI82SBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the architecture\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__() #\n",
        "        self.fc1 = nn.Linear(28*28, 50)\n",
        "        self.fc1_drop = nn.Dropout(0.2)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc2_drop = nn.Dropout(0.2)\n",
        "        self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc1_drop(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc2_drop(x)\n",
        "        return F.log_softmax(self.fc3(x), dim=1)\n",
        "\n",
        "model = Net().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            param['lr'],\n",
        "                            param['momentum'])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # cross-entropy meausers probability\n",
        "\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xh0EkU242Wyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch, log_interval=200):\n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Loop over each batch from the training set\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # Copy data to GPU if needed\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Zero gradient buffers\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Pass data through the network\n",
        "        output = model(data)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backpropagate\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
        "\n"
      ],
      "metadata": {
        "id": "PJ9MbOqD1_R0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(loss_vector, accuracy_vector):\n",
        "    model.eval()\n",
        "    val_loss, correct = 0, 0\n",
        "    for data, target in validation_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        output = model(data)\n",
        "        val_loss += criterion(output, target).data.item()\n",
        "        pred = output.data.max(1)[1] # get the index of the max log-probability\n",
        "        correct += pred.eq(target.data).cpu().sum()\n",
        "\n",
        "    val_loss /= len(validation_loader)\n",
        "    loss_vector.append(val_loss)\n",
        "\n",
        "    accuracy = 100. * correct.to(torch.float32) / len(validation_loader.dataset)\n",
        "    accuracy_vector.append(accuracy)\n",
        "\n",
        "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        val_loss, correct, len(validation_loader.dataset), accuracy))"
      ],
      "metadata": {
        "id": "5oZBuCeZ2dOm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "lossv, accv = [], []\n",
        "for epoch in range(1, param['epochs'] + 1):\n",
        "    train(epoch)\n",
        "    validate(lossv, accv)\n",
        "\n"
      ],
      "metadata": {
        "id": "n-7LlAqu2gNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot validation data and accuracy\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,param['epochs']+1), lossv)\n",
        "plt.title('validation loss')\n",
        "\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(np.arange(1,param['epochs']+1), accv)\n",
        "plt.title('validation accuracy');"
      ],
      "metadata": {
        "id": "iggjRmCn2_OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of images to evaluate\n",
        "num_images_to_evaluate = 5\n",
        "\n",
        "# Counter for evaluated images\n",
        "evaluated_images = 0\n",
        "\n",
        "# Iterate through the validation dataset\n",
        "for batch_idx, (data, target) in enumerate(validation_loader):\n",
        "    if torch.cuda.is_available():\n",
        "        data, target = data.cuda(), target.cuda()\n",
        "\n",
        "    # Forward pass\n",
        "    output = model(data)\n",
        "\n",
        "    # Get predicted labels\n",
        "    predicted = output.argmax(dim=1)\n",
        "\n",
        "    # Check if the current image is misclassified\n",
        "    for idx in range(len(target)):\n",
        "        if evaluated_images >= num_images_to_evaluate:\n",
        "            break\n",
        "\n",
        "        if predicted[idx] != target[idx]:\n",
        "            # Print the evaluation for the misclassified image\n",
        "            print(f\"Image {evaluated_images + 1} - Predicted: {predicted[idx]}, Actual: {target[idx]}\")\n",
        "\n",
        "            # Plot the misclassified digit\n",
        "            plt.imshow(data[idx].cpu().numpy().squeeze(), cmap='gray')\n",
        "            plt.title(f\"Predicted: {predicted[idx]}, Actual: {target[idx]}\")\n",
        "            plt.show()\n",
        "\n",
        "            evaluated_images += 1\n",
        "\n",
        "    if evaluated_images >= num_images_to_evaluate:\n",
        "        break"
      ],
      "metadata": {
        "id": "NkeSxELxX4hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bi_mz44iaSut"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}